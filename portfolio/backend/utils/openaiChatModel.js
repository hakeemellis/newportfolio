//  utils/openaiChatModel.js

// Handles AI-powered features using OpenAI (GPT-3.5-turbo)

// Import Application Modules
const { response } = require("express");
const openai = require("../config/openai");

// Define OpenAI Chat Model for generating tags based on descriptions
const openAIChatModel = async (description) => {
  // Defining the parameter "description" for the AI to generate tags based on it being called in openaiRoutes.js

  // To show openai properties
  console.log(openai);

  try {
    // Defining access to the OpenAI API for text generation/completion
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo", // model in use for text generation/completion
      messages: [
        // messages used for defining the AI's role and the user's role
        // essentially mimics a continious conversation with the same prompt to the AI
        {
          role: "system", // role of the AI (server)
          content:
            "You are a helpful AI that generates relevant tags based on descriptions.", // letting the AI know its role
        },
        {
          role: "user", // role of the user (client)
          content: `Generate a list of relevant tags for the following description: "${description}"`, // asking the AI what to do
        }, // description is defined in openaiRoutes.js
      ],
      max_tokens: 50, // limits token response by AI to 50 - to prevent overly long responses
      temperature: 0.5, // sets AI's behavior essentially - 0.5 is a good balance between creativity and coherence
    });

    // res.json({ response }); // send response in JSON format - curly braces in this case just to show it's from "response" in JSON format
    // kept to show information being pumped out by the AI

    // From response (AI), extract tags from response
    const tags = (response.choices[0]?.message?.content || "") // used this syntax to extract content from JSON response as defined by { response }
      .replace(/\r\n/g, "\n") // uses regex to replace \r\n (with \r being carriage return and \n being new line) with \n
      .trim() // uses trim method to remove any whitespace from the tags
      .split(/\n|,\s*/) // uses split method to split the tags by new line
      .map((tag) => tag.replace(/^\s*-\s*/, "").trim()) // uses regex to remove the "-" (using replace method) and any whitespace left from deleting the "-" (using trim method)
      .filter((tag) => tag.toLowerCase() !== "undefined")
      .slice(0, 13); // Limits answers/tags to 13 (but this only relates to showing on the backend - basically our JSON response)

    // Returns tags generated by the AI
    return tags;
  } catch (error) {
    console.error("Error generating tags:", error);
    res.status(500).json({ error: "Failed to generate tags" });
  }
};

// Define OpenAI Chat Model for generating sector tags based on all project descriptions
const openAIChatModelForSectors = async (description) => {
  // Defining the parameter "description" for the AI to generate sector tags based on it being called in openaiRoutes.js

  // To show openai properties
  console.log(openai);

  try {
    // Defining access to the OpenAI API for text generation/completion
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo", // model in use for text generation/completion
      messages: [
        // messages used for defining the AI's role and the user's role
        // essentially mimics a continuous conversation with the same prompt to the AI
        {
          role: "system", // role of the AI (server)
          content:
            "You are a helpful AI that generates relevant sector tags based on aggregated project descriptions.", // letting the AI know its role
        },
        {
          role: "user", // role of the user (client)
          content: `Generate a list of relevant sector tags for the following aggregated project descriptions: "${description}"`, // asking the AI what to do
        }, // description is defined in openaiRoutes.js
      ],
      max_tokens: 50, // limits token response by AI to 50 - to prevent overly long responses
      temperature: 0.5, // sets AI's behavior essentially - 0.5 is a good balance between creativity and coherence
    });

    // From response (AI), extract sector tags from response
    const sectorTags = (response.choices[0]?.message?.content || "")
      .replace(/\r\n/g, "\n") // uses regex to replace \r\n (with \r being carriage return and \n being new line) with \n
      .trim() // uses trim method to remove any whitespace from the tags
      .split(/\n|,\s*/) // uses split method to split the tags by new line
      .map((tag) => tag.replace(/^\s*-\s*/, "").trim()) // uses regex to remove the "-" (using replace method) and any whitespace left from deleting the "-" (using trim method)
      .filter((tag) => tag.toLowerCase() !== "undefined")
      .slice(0, 13); // Limits answers/tags to 13 (but this only relates to showing on the backend - basically our JSON response)

    // Returns sector tags generated by the AI
    return sectorTags;
  } catch (error) {
    console.error("Error generating sector tags:", error);
    throw new Error("Failed to generate sector tags");
  }
};

module.exports = { openAIChatModel, openAIChatModelForSectors }; // Export as modular variables
